# Attention

The following attention models are implemented in pytorch.

## Environment

>python 3.7
>
>pytorch 1.9.1

## Different Attention Mechanisms

>1-Attention 注意力机制
>
>2-MultiAttention 多头注意力机制
>
>3-MultiSelfAttention 多头自注意力机制
>
>4-AtrousSelfAttention 空洞多头注意力机制
>
>5-LocalSelfAttention 局部多头注意力机制
>
>6-SparseSelfAttention 稀疏多头注意力机制

## References

1.https://github.com/bojone/attention

2.https://kexue.fm/archives/6853
